{
  "models": {
    "gemini-pro": {
      "litellm_string": "gemini/gemini-2.5-pro",
      "provider": "Google",
      "description": "Most capable Gemini model",
      "context_length": 1000000,
      "use_case": "Complex reasoning and long context"
    },
    "gemini-flash": {
      "litellm_string": "gemini/gemini-2.5-flash",
      "provider": "Google",
      "description": "Fast and efficient Gemini model",
      "context_length": 1000000,
      "use_case": "Quick responses and general tasks"
    },
    "gemini-flash-lite": {
      "litellm_string": "gemini/gemini-2.5-flash-lite",
      "provider": "Google",
      "description": "Lightweight Gemini model",
      "context_length": 1000000,
      "use_case": "Simple, fast queries"
    },
    "gpt120b": {
      "litellm_string": "groq/openai/gpt-oss-120b",
      "provider": "Groq",
      "description": "Large open-source model on Groq",
      "context_length": 32768,
      "use_case": "High-quality responses with speed"
    },
    "gpt20b": {
      "litellm_string": "groq/openai/gpt-oss-20b",
      "provider": "Groq",
      "description": "Smaller open-source model on Groq",
      "context_length": 32768,
      "use_case": "Fast, efficient responses"
    },
    "compound_mini": {
      "litellm_string": "groq/groq/compound-mini",
      "provider": "Groq",
      "description": "Groq's compound mini model",
      "context_length": 8192,
      "use_case": "Quick tasks"
    },
    "llama33versatile": {
      "litellm_string": "groq/llama-3.3-70b-versatile",
      "provider": "Groq",
      "description": "Versatile Llama 3.3 model",
      "context_length": 32768,
      "use_case": "General-purpose conversations"
    },
    "llama31instant": {
      "litellm_string": "groq/llama-3.1-8b-instant",
      "provider": "Groq",
      "description": "Ultra-fast Llama model",
      "context_length": 8192,
      "use_case": "Instant responses"
    },
    "magmedium1": {
      "litellm_string": "mistral/magistral-medium-2506",
      "provider": "Mistral",
      "description": "Mistral medium-sized model",
      "context_length": 32768,
      "use_case": "Balanced performance"
    },
    "medium31": {
      "litellm_string": "mistral/mistral-medium-2508",
      "provider": "Mistral",
      "description": "Latest Mistral medium model",
      "context_length": 32768,
      "use_case": "General tasks"
    },
    "magsmall": {
      "litellm_string": "mistral/magistral-small-2506",
      "provider": "Mistral",
      "description": "Small, efficient Mistral model",
      "context_length": 32768,
      "use_case": "Quick, simple queries"
    },
    "opennemo": {
      "litellm_string": "mistral/open-mistral-nemo",
      "provider": "Mistral",
      "description": "Open Mistral Nemo model",
      "context_length": 32768,
      "use_case": "Open-source tasks"
    }
  }
}